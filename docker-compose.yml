
# 自定义网络：所有服务在同一网络，用容器名直接访问
networks:
  stock-network:
    driver: bridge

# 数据卷：持久化MySQL数据和Grafana配置
volumes:
  mysql-data:  # 保存MySQL数据（容器删除后数据不丢）
  grafana-storage:  # 保存Grafana仪表盘和配置

services:
  # 1. MySQL 服务（适配你的MYSQL_*配置）
  mysql:
    image: swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/mysql/mysql-server:8.0.32
    container_name: stock-mysql
    env_file:
      - ./.env
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}  # 从.env读取
      MYSQL_DATABASE: ${MYSQL_DATABASE}            # 自动创建数据库
      MYSQL_USER: ${MYSQL_USER}                    # 从.env读取
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}            # 从.env读取
    ports:
      - "3306:3306"  # 本地端口映射（方便本地连接调试）
    volumes:
      - mysql-data:/var/lib/mysql
    networks:
      - stock-network
    restart: always  # 服务异常自动重启

  # 2. Zookeeper（Kafka依赖，无需修改）
  zookeeper:
    image: swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/confluentinc/cp-zookeeper:7.7.0
    container_name: stock-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - stock-network
    restart: always

  # 3. Kafka 服务（适配你的KAFKA_*配置）
  kafka:
    image: swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/confluentinc/cp-kafka:7.5.0
    container_name: kafka-broker
    platform: linux/amd64
    depends_on:
      - zookeeper  # 先启动Zookeeper再启动Kafka
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181  # 连接同一网络的Zookeeper
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
      KAFKA_LOG_RETENTION_HOURS: 720
      KAFKA_LOG_RETENTION_BYTES: 100000000000
    ports:
      - "9092:9092"  # 本地端口映射（方便本地脚本发送数据）
      - "9093:9093"
    networks:
      - stock-network
    restart: always

  # 4. Spark 服务（运行数据处理脚本）
  spark:
    image: swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/bitnami/spark:3.5.3
    container_name: stock-spark
    depends_on:
      - kafka
      - mysql
    env_file:
      - ./.env
    environment:
      # 从.env读取连接信息（直接用容器名访问Kafka/MySQL）
      KAFKA_SERVER: ${KAFKA_SERVER}
      KAFKA_TOPIC: ${KAFKA_TOPIC}
      MYSQL_HOST: ${MYSQL_HOST}
      MYSQL_PORT: ${MYSQL_PORT}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    volumes:
      # 挂载本地Spark代码到容器内（修改本地代码无需重建镜像）
      - ./Spark:/app/Spark
    command: >
      bash -c "
      # 等待Kafka和MySQL就绪（避免启动太快连接失败）
      sleep 20 &&
      # 提交Spark作业（指定依赖包，和你本地运行的一致）
      spark-submit 
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,mysql:mysql-connector-java:8.0.33 
      /app/Spark/DataProcess.py
      "
    networks:
      - stock-network
    restart: on-failure  # 作业失败自动重试

  # 5. Grafana 服务（可视化数据）
  grafana:
    image: swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/grafana/grafana:10.2.2
    container_name: stock-grafana
    depends_on:
      - mysql  # 先启动MySQL再启动Grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}  # 从.env读取登录密码
      GF_USERS_ALLOW_SIGN_UP: false  # 禁止注册
    ports:
      - "3000:3000"  # Grafana默认端口（本地访问用）
    volumes:
      # 挂载本地Grafana配置（数据源+仪表盘）
      - ./grafana/provisioning:/etc/grafana/provisioning
      - grafana-storage:/var/lib/grafana
    networks:
      - stock-network
    restart: always